{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TF_Serving_Learner.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBFQ0nftW6_U"
      },
      "source": [
        "<h2 align=\"center\"> Deploy Models with TensorFlow Serving and Docker</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcF4jsZcW6_V"
      },
      "source": [
        "### Load and Preprocess Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQhSNW-CZUZh"
      },
      "source": [
        "#%%writefile -a train.py\n",
        "import os\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP5PFge9W6_V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6d8201-aa00-4180-86e0-4f068fd6b31c"
      },
      "source": [
        "#Souce: https://www.kaggle.com/snap/amazon-fine-food-reviews/data\n",
        "!head -n 2 train.csv"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Id,ProductId,UserId,ProfileName,HelpfulnessNumerator,HelpfulnessDenominator,Score,Time,Summary,Text\n",
            "184502,B001BCVY4W,A1JMR1N9NBYJ1X,Mad Ethyl Flint,0,0,4,1228176000,Doesn't look like catfood!,\"When you first open the can, it looks like something you would eat.  And no catfood smell! Nice sized chunks of chicken and vegetables in a lot of gravy.<br /><br />That being said, Ms Casiopia lapped up all the gravy and left the rest.  This however is not the product's fault as she has done this before with other catfoods<br /><br />I would have given it 5 stars, but since I won't be purchasing it, I gave it 4.  If your cat will eat chunks and vegetables, this product is for you.<br /><br />I have donated the remainder of the package to a less fortunate friend.<br /><br />Thank you.\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WVjUe_uAW6_V"
      },
      "source": [
        "#%%writefile -a train.py\n",
        "def load_dataset(file_path,num_sample):\n",
        "  df=pd.read_csv(file_path,usecols=[6,9],nrows=num_sample)\n",
        "  df.columns=['rating','title']\n",
        "\n",
        "  text=df['title'].tolist()\n",
        "  text=[str(t).encode('ascii','replace') for t in text]\n",
        "  text=np.array(text,dtype=object)\n",
        "\n",
        "  labels=df['rating'].tolist()\n",
        "  labels=[1 if i>=4 else 0 if i==3 else -1 for i in labels]\n",
        "  labels=np.array(pd.get_dummies(labels),dtype=int)\n",
        "\n",
        "  return labels,text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TL7zusZbW6_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36424b3a-40d0-4f3c-b8bd-59cc2abad074"
      },
      "source": [
        "tmp_label,tmp_text= load_dataset('train.csv',100)\n",
        "tmp_label.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB_L1sZUW6_W"
      },
      "source": [
        "### Task 3: Build the Classification Model using TF Hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuaKSE0DW6_W"
      },
      "source": [
        "#%%writefile -a train.py\n",
        "\n",
        "## https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\n",
        "## https://tfhub.dev/google/tf2-preview/nnlm-en-dim128/1\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TRvz7DqW6_W"
      },
      "source": [
        "def get_model():\n",
        "  pretrained_model = 'https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1'\n",
        "  hub_layer = hub.KerasLayer(pretrained_model, output_shape=[50], input_shape = [], dtype=tf.string, trainable=False)\n",
        "  model=tf.keras.Sequential()\n",
        "  model.add(hub_layer)\n",
        "  model.add(tf.keras.layers.Dense(16,activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(3,activation=\"softmax\"))\n",
        "  model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "  model.summary()\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lt6QJot8W6_W"
      },
      "source": [
        "###  Define Training Procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3Qo8dD6W6_W"
      },
      "source": [
        "#%%writefile -a train.py\n",
        "def train(EPOCHS=5, BATCH_SIZE=32, TRAIN_FILE='train.csv', VAL_FILE='test.csv'):\n",
        "  WORKING_DIR= os.getcwd()\n",
        "  print(\"Loading training/validation data ...\")\n",
        "  y_train,x_train=load_dataset(TRAIN_FILE,num_sample=100000)\n",
        "  y_val,x_val=load_dataset(VAL_FILE,num_sample=10000)\n",
        "\n",
        "  print(\"Training the model ...\")\n",
        "  model=get_model()\n",
        "  model.fit(x_train,y_train,\n",
        "          epochs=EPOCHS,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          validation_data=(x_val,y_val),\n",
        "          verbose=1,\n",
        "          callbacks=[tf.keras.callbacks.ModelCheckpoint(os.path.join(WORKING_DIR),'model_checkpoint',\n",
        "                                                        \n",
        "                                                        verbose=1,\n",
        "                                                        save_best_only=True,\n",
        "                                                        save_weights_only=False,\n",
        "                                                        mode='auto')])\n",
        "  return model\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QUQSBHAW6_W"
      },
      "source": [
        "###  Train and Export Model as Protobuf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbVLR6ALW6_W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f918133-1f36-4731-9049-f342ade0d0f6"
      },
      "source": [
        "#%%writefile -a train.py\n",
        "def export_model(model,base_path='amazon_review/'):\n",
        "  path=os.path.join(base_path,str(int(time.time())))\n",
        "  tf.saved_model.save(model,path)\n",
        "\n",
        "if __name__=='__main__':\n",
        "  model=train()\n",
        "  export_model(model)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading training/validation data ...\n",
            "Training the model ...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "keras_layer (KerasLayer)     (None, 50)                48190600  \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 16)                816       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 51        \n",
            "=================================================================\n",
            "Total params: 48,191,467\n",
            "Trainable params: 867\n",
            "Non-trainable params: 48,190,600\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "247/247 [==============================] - 5s 9ms/step - loss: 0.7533 - accuracy: 0.7490 - val_loss: 0.6561 - val_accuracy: 0.7838\n",
            "WARNING:tensorflow:Can save best model only with model_checkpoint available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with model_checkpoint available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/5\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.6377 - accuracy: 0.7787 - val_loss: 0.6144 - val_accuracy: 0.7838\n",
            "WARNING:tensorflow:Can save best model only with model_checkpoint available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with model_checkpoint available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/5\n",
            "247/247 [==============================] - 2s 10ms/step - loss: 0.6059 - accuracy: 0.7787 - val_loss: 0.6002 - val_accuracy: 0.7837\n",
            "WARNING:tensorflow:Can save best model only with model_checkpoint available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with model_checkpoint available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/5\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.5925 - accuracy: 0.7787 - val_loss: 0.5882 - val_accuracy: 0.7846\n",
            "WARNING:tensorflow:Can save best model only with model_checkpoint available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with model_checkpoint available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/5\n",
            "247/247 [==============================] - 2s 8ms/step - loss: 0.5843 - accuracy: 0.7815 - val_loss: 0.5848 - val_accuracy: 0.7861\n",
            "WARNING:tensorflow:Can save best model only with model_checkpoint available, skipping.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Can save best model only with model_checkpoint available, skipping.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: amazon_review/1629286458/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: amazon_review/1629286458/assets\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK0YpPF-W6_X"
      },
      "source": [
        "### Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAfbNqnNW6_X"
      },
      "source": [
        "#### Negative Review:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFDjXYODW6_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f1d9110-b230-462f-ee9d-72f78e7c5f56"
      },
      "source": [
        "test_sentence=\"Horrible movie\"\n",
        "model.predict([test_sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.16203047, 0.03660675, 0.8013628 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slncZEPFW6_X"
      },
      "source": [
        "#### Positive Review:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFqncMifW6_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0895ff31-9b92-40f7-d9a2-8321628d96ea"
      },
      "source": [
        "test_sentence=\"Great movie\"\n",
        "model.predict([test_sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.03136075, 0.01278753, 0.9558517 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF31Qh8sW6_X"
      },
      "source": [
        "### TensorFlow Serving with Docker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJZcSm4YW6_X"
      },
      "source": [
        "`docker pull tensorflow/serving`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqqlN7hUW6_X"
      },
      "source": [
        "`docker run -p 8500:8500 \\\n",
        "            -p 8501:8501 \\\n",
        "            --mount type=bind,\\\n",
        "            source=amazon_review/,\\\n",
        "            target=/models/amazon_review \\\n",
        "            -e MODEL_NAME=amazon_review \\\n",
        "            -t tensorflow/serving`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3bdcRy5W6_Y"
      },
      "source": [
        "### Setup a REST Client to Perform Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NND75SMZUsP"
      },
      "source": [
        "%%writefile tf_serving_rest_client.py\n",
        "import json\n",
        "import requests\n",
        "import sys\n",
        "\n",
        "def get_rest_url(model_name, host='127.0.0.1', port='8501', verb='predict', version=None):\n",
        "    \"\"\" generate the URL path\"\"\"\n",
        "    url = \"http://{host}:{port}/v1/models/{model_name}\".format(host=host, port=port, model_name=model_name)\n",
        "    if version:\n",
        "        url += 'versions/{version}'.format(version=version)\n",
        "    url += ':{verb}'.format(verb=verb)\n",
        "    return url\n",
        "\n",
        "\n",
        "def get_model_prediction(model_input, model_name='amazon_review', signature_name='serving_default'):\n",
        "    \"\"\" no error handling at all, just poc\"\"\"\n",
        "\n",
        "    url = get_rest_url(model_name)\n",
        "    #In the row format, inputs are keyed to instances key in the JSON request.\n",
        "    #When there is only one named input, specify the value of instances key to be the value of the input:\n",
        "    data = {\"instances\": [model_input]}\n",
        "    \n",
        "    rv = requests.post(url, data=json.dumps(data))\n",
        "    if rv.status_code != requests.codes.ok:\n",
        "        rv.raise_for_status()\n",
        "    \n",
        "    return rv.json()['predictions']\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "    print(\"\\nGenerate REST url ...\")\n",
        "    url = get_rest_url(model_name='amazon_review')\n",
        "    print(url)\n",
        "    \n",
        "    while True:\n",
        "        print(\"\\nEnter an Amazon review [:q for Quit]\")\n",
        "        if sys.version_info[0] <= 3:\n",
        "            sentence = input()\n",
        "        if sentence == ':q':\n",
        "            break\n",
        "        model_input = sentence\n",
        "        model_prediction = get_model_prediction(model_input)\n",
        "        print(\"The model predicted ...\")\n",
        "        print(model_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqT3_kCgW6_Y"
      },
      "source": [
        "### Setup a gRPC Client to Perform Model Predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jKJVOjDlZUvc"
      },
      "source": [
        "%%writefile tf_serving_grpc_client.py\n",
        "import sys\n",
        "import grpc\n",
        "from grpc.beta import implementations\n",
        "import tensorflow as tf\n",
        "from tensorflow_serving.apis import predict_pb2\n",
        "from tensorflow_serving.apis import prediction_service_pb2, get_model_metadata_pb2\n",
        "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
        "\n",
        "\n",
        "def get_stub(host='127.0.0.1', port='8500'):\n",
        "    channel = grpc.insecure_channel('127.0.0.1:8500') \n",
        "    stub = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
        "    return stub\n",
        "\n",
        "\n",
        "def get_model_prediction(model_input, stub, model_name='amazon_review', signature_name='serving_default'):\n",
        "    \"\"\" no error handling at all, just poc\"\"\"\n",
        "    request = predict_pb2.PredictRequest()\n",
        "    request.model_spec.name = model_name\n",
        "    request.model_spec.signature_name = signature_name\n",
        "    request.inputs['input_input'].CopyFrom(tf.make_tensor_proto(model_input))\n",
        "    response = stub.Predict.future(request, 5.0)  # 5 seconds\n",
        "    return response.result().outputs[\"output\"].float_val\n",
        "\n",
        "\n",
        "def get_model_version(model_name, stub):\n",
        "    request = get_model_metadata_pb2.GetModelMetadataRequest()\n",
        "    request.model_spec.name = 'amazon_review'\n",
        "    request.metadata_field.append(\"signature_def\")\n",
        "    response = stub.GetModelMetadata(request, 10)\n",
        "    # signature of loaded model is available here: response.metadata['signature_def']\n",
        "    return response.model_spec.version.value\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print(\"\\nCreate RPC connection ...\")\n",
        "    stub = get_stub()\n",
        "    while True:\n",
        "        print(\"\\nEnter an Amazon review [:q for Quit]\")\n",
        "        if sys.version_info[0] <= 3:\n",
        "            sentence = raw_input() if sys.version_info[0] < 3 else input()\n",
        "        if sentence == ':q':\n",
        "            break\n",
        "        model_input = [sentence]\n",
        "        model_prediction = get_model_prediction(model_input, stub)\n",
        "        print(\"The model predicted ...\")\n",
        "        print(model_prediction)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TidfRe2VZU39"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xA3wNmDSZU66"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}